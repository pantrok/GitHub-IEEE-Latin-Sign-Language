{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Utils"
      ],
      "metadata": {
        "id": "ed6tlgfLOBLk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to Google Drive"
      ],
      "metadata": {
        "id": "-f5qt02UOm38"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "D7NjZ61yOqJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Label the files with the correct meaning of a sign for LIBRAS"
      ],
      "metadata": {
        "id": "5fj1stijOGNL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxQTHjdZN_vK"
      },
      "outputs": [],
      "source": [
        "!pip install pympi-ling"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pympi.Elan as Elan\n",
        "import math\n",
        "\n",
        "video_str = 'FLN_G1_D4_VOCAB_2Alimentos_VIDEO2'\n",
        "eaf_str = 'FLN_G1_D4_VOCAB_2Alimentos_VIDEO1234'\n",
        "fps = 30\n",
        "fpms = fps / 1000\n",
        "df = pd.read_excel('/content/gdrive/My Drive/your_directory/LIBRAS Data/'+video_str+'_all_output_07102022.xlsx', index_col=0)\n",
        "elan_object = Elan.Eaf(file_path = '/content/gdrive/My Drive/your_directory/LIBRAS Data/'+eaf_str+'.eaf')\n",
        "xml_rhlabel = \"1SinaisD\"\n",
        "#xml_rhlabel = \"RH-IDgloss\"\n",
        "xml_lhlabel = \"1SinaisE\"\n",
        "#xml_lhlabel = \"LH-IDgloss\"\n",
        "# iterate through each row and select \n",
        "#df.drop('class',  axis='columns', inplace=True)\n",
        "#df.drop('video', axis='columns', inplace=True)\n",
        "df[\"label\"] = None\n",
        "\n",
        "for i in range(len(df)) :\n",
        "  frame = df[\"frame\"][i]\n",
        "  #print(f'Frame {frame}')\n",
        "  for annotation in elan_object.get_annotation_data_for_tier(xml_rhlabel):\n",
        "    #print(annotation)\n",
        "    # We are interested in the utterance\n",
        "    utterance = annotation[2].strip().lower()\n",
        "    start_time = int(annotation[0])\n",
        "    end_time = int(annotation[1])\n",
        "    start_frame = math.ceil(start_time * fpms)\n",
        "    end_frame = math.ceil(end_time * fpms)\n",
        "    if frame >= start_frame and frame <= end_frame:\n",
        "      df[\"label\"][i] = utterance\n",
        "      break\n",
        "  if df[\"label\"][i] == None:\n",
        "    for annotation in elan_object.get_annotation_data_for_tier(xml_lhlabel):\n",
        "    #print(annotation)\n",
        "    # We are interested in the utterance\n",
        "      utterance = annotation[2].strip().lower()\n",
        "      start_time = int(annotation[0])\n",
        "      end_time = int(annotation[1])\n",
        "      start_frame = math.ceil(start_time * fpms)\n",
        "      #df[\"start_frame\"][i] = str(start_time) + \"->\" +  str(start_frame)\n",
        "      end_frame = math.ceil(end_time * fpms)\n",
        "      #df[\"end_frame\"][i] = str(end_time) + \"->\" +  str(end_frame)\n",
        "      if frame >= start_frame and frame <= end_frame:\n",
        "        df[\"label\"][i] = utterance\n",
        "        break\n",
        "  if df[\"label\"][i] == None:\n",
        "    df[\"label\"][i] = 'blank_transition'\n",
        "\n",
        "df.drop('frame',\n",
        "  axis='columns', inplace=True)\n",
        "}df.to_excel(\"/content/gdrive/My Drive/your_directory/LIBRAS Data/\"+video_str+\"_fortraining_output_07102022.xlsx\")  "
      ],
      "metadata": {
        "id": "cq1YZZyLOLXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Merge different features in one file"
      ],
      "metadata": {
        "id": "9cFEDDYQft9M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "video_str = '01067'\n",
        "#df = pd.read_excel('/content/gdrive/My Drive/Doctorado/Programa Tesis/Avances Otoño 2022/LIBRAS Data/'+ video_str +'_faceposture_output_07102022_1aug.xlsx', index_col=0)\n",
        "#df_gaze = pd.read_excel('/content/gdrive/My Drive/Doctorado/Programa Tesis/Avances Otoño 2022/LIBRAS Data/'+ video_str +'_gazehead_output_17102022.xlsx', index_col=0)\n",
        "#df_speed = pd.read_excel('/content/gdrive/My Drive/Doctorado/Programa Tesis/Avances Otoño 2022/LIBRAS Data/'+ video_str +'_hands_output_17102022.xlsx', index_col=0)\n",
        "df = pd.read_excel('/content/gdrive/My Drive/Doctorado/Programa Tesis/Avances Primavera 2023/WLASL/Data/'+ video_str +'_faceposture_output_25012023_1aug.xlsx', index_col=0)\n",
        "df_gaze = pd.read_excel('/content/gdrive/My Drive/Doctorado/Programa Tesis/Avances Primavera 2023/WLASL/Data/'+ video_str +'_gazehead_output_25012023.xlsx', index_col=0)\n",
        "df_speed = pd.read_excel('/content/gdrive/My Drive/Doctorado/Programa Tesis/Avances Primavera 2023/WLASL/Data/'+ video_str +'_hands_output_25012023.xlsx', index_col=0)\n",
        "df_speed = df_speed.drop([0], axis=1)\n",
        "column_names_df = df.columns.values.tolist()\n",
        "last_column_name = column_names_df[-1]\n",
        "indexes_gaze = []\n",
        "for index in range(len(df_gaze.columns.values.tolist())):\n",
        "  df[last_column_name+index+1] = 0\n",
        "  indexes_gaze.append(last_column_name+index+1)\n",
        "column_names_df = df.columns.values.tolist()\n",
        "last_column_name = column_names_df[-1]\n",
        "indexes_speed = []\n",
        "for index in range(len(df_speed.columns.values.tolist())):\n",
        "  df[last_column_name+index+1] = 0\n",
        "  indexes_speed.append(last_column_name+index+1)\n",
        "#print(indexes_gaze)\n",
        "#print(indexes_speed)\n",
        "#df.head()\n",
        "count, count_aug = 0, 1\n",
        "INCREASE_COUNT = False\n",
        "count_total = 0\n",
        "prev_frame = df.iloc[count_total, 0]\n",
        "for index, row in df.iterrows():\n",
        "    #if count > 26:\n",
        "    #  break\n",
        "    #print(count_total)\n",
        "    #print(count)\n",
        "    frame = df.iloc[count_total, 0]\n",
        "    if prev_frame != frame:\n",
        "      prev_frame = frame\n",
        "      count += 1\n",
        "    df.iloc[count_total, indexes_gaze] = df_gaze.iloc[count].tolist()\n",
        "    count_total += 1\n",
        "count, count_aug = 0, 1\n",
        "INCREASE_COUNT = False\n",
        "count_total = 0\n",
        "prev_frame = df.iloc[count_total, 0]\n",
        "for index, row in df.iterrows():\n",
        "    #if count > 537:\n",
        "    #  break\n",
        "    #print(count)\n",
        "    frame = df.iloc[count_total, 0]\n",
        "    if prev_frame != frame:\n",
        "      prev_frame = frame\n",
        "      count += 1\n",
        "    df.iloc[count_total, indexes_speed] = df_speed.iloc[count].tolist()\n",
        "    count_total += 1\n",
        "\n",
        "df.to_excel(\"/content/gdrive/My Drive/Doctorado/Programa Tesis/Avances Primavera 2023/WLASL/Data/\"+ video_str +\"_all_output_25012023.xlsx\")\n",
        "#X = df.drop(\"label\", axis=1)"
      ],
      "metadata": {
        "id": "6W_5i7Bmf0Uo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate CSV files with correct format for Transformer"
      ],
      "metadata": {
        "id": "edTNsCDrl6Y7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pympi-ling"
      ],
      "metadata": {
        "id": "MGuXnkznl9AP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pympi.Elan as Elan\n",
        "import math\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "video_str = 'FLN_G1_D1_VOCAB_1Família_VIDEO3'\n",
        "eaf_str = 'FLN_G1_D1_VOCAB_1Família_VIDEO123'\n",
        "fps = 30\n",
        "fpms = fps / 1000\n",
        "\n",
        "df = pd.read_excel('/content/gdrive/My Drive/your_directory/LIBRAS Data/'+video_str+'_all_output_09092022.xlsx', index_col=0)\n",
        "elan_object = Elan.Eaf(file_path = '/content/gdrive/My Drive/your_directory/LIBRAS Data/'+eaf_str+'.eaf')\n",
        "xml_rhlabel = \"2Sinais D\"\n",
        "#xml_rhlabel = \"RH-IDgloss\"\n",
        "xml_lhlabel = \"2Sinais E\"\n",
        "#xml_lhlabel = \"LH-IDgloss\"\n",
        "\n",
        "#ss = StandardScaler()\n",
        "ss = MinMaxScaler()\n",
        "X = df.drop(\"frame\", axis=1) # Create a data with all columns except labels\n",
        "X_scaled = ss.fit_transform(X)\n",
        "pca = PCA(0.95)\n",
        "pca.fit(X_scaled)\n",
        "X_scaled = pca.transform(X_scaled)\n",
        "print(df.shape)\n",
        "print(X_scaled.shape)\n",
        "\n",
        "features_matrix_orig = []\n",
        "features_matrix_aug = []\n",
        "columns = []\n",
        "for i in range(X_scaled.shape[1]):\n",
        "  features_matrix_orig.append([])\n",
        "  features_matrix_aug.append([])\n",
        "  columns.append(i)\n",
        "class_prev = \"\"\n",
        "class_current = \"\"\n",
        "#create empty dataframe\n",
        "df_transformer = pd.DataFrame(columns=columns)\n",
        "# iterate through each row and select \n",
        "for i in range(0, len(df), 2) :\n",
        "  frame = df[\"frame\"][i]\n",
        "  #print(f'Frame {frame}')\n",
        "  for annotation in elan_object.get_annotation_data_for_tier(xml_rhlabel):\n",
        "    #print(annotation)\n",
        "    # We are interested in the utterance\n",
        "    utterance = annotation[2].strip().lower()\n",
        "    start_time = int(annotation[0])\n",
        "    end_time = int(annotation[1])\n",
        "    start_frame = math.ceil(start_time * fpms)\n",
        "    end_frame = math.ceil(end_time * fpms)\n",
        "    if frame >= start_frame and frame <= end_frame:\n",
        "      class_current = utterance\n",
        "      break\n",
        "  if class_current == \"\":\n",
        "    for annotation in elan_object.get_annotation_data_for_tier(xml_lhlabel):\n",
        "    #print(annotation)\n",
        "    # We are interested in the utterance\n",
        "      utterance = annotation[2].strip().lower()\n",
        "      start_time = int(annotation[0])\n",
        "      end_time = int(annotation[1])\n",
        "      start_frame = math.ceil(start_time * fpms)\n",
        "      #df[\"start_frame\"][i] = str(start_time) + \"->\" +  str(start_frame)\n",
        "      end_frame = math.ceil(end_time * fpms)\n",
        "      #df[\"end_frame\"][i] = str(end_time) + \"->\" +  str(end_frame)\n",
        "      if frame >= start_frame and frame <= end_frame:\n",
        "        class_current = utterance\n",
        "        break\n",
        "  #print(class_current)\n",
        "  if class_current == \"\":\n",
        "    class_current = 'blank_transition'\n",
        "  \n",
        "  if class_prev == \"\":\n",
        "    class_prev = class_current\n",
        "  #print(class_prev, class_current)\n",
        "  if class_current == class_prev:\n",
        "      #Checar si es la misma clase, si es la misma seguir haciendo append de las features\n",
        "      for j in range(X_scaled.shape[1]):\n",
        "        features_matrix_orig[j].append(X_scaled[i, j ])\n",
        "        features_matrix_aug[j].append(X_scaled[(i + 1), j ])\n",
        "  else:\n",
        "      #sino generar los series y hacer el append al dataframe de la row\n",
        "      row_dict_orig, row_dict_aug = {}, {}\n",
        "      for k in range(X_scaled.shape[1]):\n",
        "        row_dict_orig[k] = features_matrix_orig[k]\n",
        "        row_dict_aug[k] = features_matrix_aug[k]\n",
        "      row_dict_orig[\"class\"] = class_current\n",
        "      row_dict_aug[\"class\"] = class_current\n",
        "      #print(features_matrix_orig)\n",
        "      df_transformer = df_transformer.append(row_dict_orig, ignore_index=True)\n",
        "      df_transformer = df_transformer.append(row_dict_aug, ignore_index=True)\n",
        "      for i in range(df.shape[1] - 1):\n",
        "        features_matrix_orig.append([])\n",
        "        features_matrix_aug.append([])\n",
        "        columns.append(i)\n",
        "      class_prev = class_current\n",
        "  \n",
        "  class_current = \"\"\n",
        "\n",
        "#df_transformer.head(5)\n",
        "df_transformer.to_excel(\"/content/gdrive/My Drive/your_directory/LIBRAS Data/\"+video_str+\"_fortransformer_output_17102022.xlsx\")"
      ],
      "metadata": {
        "id": "uGBJNzYXOefT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import required module\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.decomposition import PCA\n",
        "import os\n",
        "import numpy as np\n",
        "# assign directory\n",
        "directory = '/content/gdrive/My Drive/your_directory/LIBRAS Data/'\n",
        " \n",
        "# iterate over files in\n",
        "# that directory\n",
        "df_main = None\n",
        "for filename in os.listdir(directory):\n",
        "    f = os.path.join(directory, filename)\n",
        "    # checking if it is a file\n",
        "    if os.path.isfile(f) and ('fortraining_output_07102022.xlsx' in f or 'fortraining_output_09092022' in f):\n",
        "        print(f)\n",
        "        df = pd.read_excel(f, index_col=0)\n",
        "        if df_main is None:\n",
        "          df_main = df.copy()\n",
        "        else:\n",
        "          df_main = df_main.append(df, ignore_index=True)\n",
        "\n",
        "df_main.to_excel(\"/content/gdrive/My Drive/your_directory/LIBRAS Data/All_Vocab_28112022.xlsx\")\n",
        "\n",
        "ss = MinMaxScaler()\n",
        "X = df_main.drop(\"label\", axis=1) # Create a data with all columns except labels\n",
        "X_scaled = ss.fit_transform(X)\n",
        "pca = PCA(0.96)\n",
        "pca.fit(X_scaled)\n",
        "X_scaled = pca.transform(X_scaled)\n",
        "\n",
        "features_matrix_orig = []\n",
        "features_matrix_aug = []\n",
        "columns = []\n",
        "for i in range(X_scaled.shape[1]):\n",
        "  features_matrix_orig.append([])\n",
        "  features_matrix_aug.append([])\n",
        "  columns.append(i)\n",
        "class_prev = \"\"\n",
        "class_current = \"\"\n",
        "#create empty dataframe\n",
        "df_transformer = pd.DataFrame(columns=columns)\n",
        "# iterate through each row and select \n",
        "for i in range(0, len(df_main), 2) :\n",
        "  class_current = df_main[\"label\"][i]\n",
        "  if class_prev == \"\":\n",
        "    class_prev = class_current\n",
        "  #print(class_prev, class_current)\n",
        "  if class_current == class_prev:\n",
        "      #Checar si es la misma clase, si es la misma seguir haciendo append de las features\n",
        "      for j in range(X_scaled.shape[1]):\n",
        "        features_matrix_orig[j].append(X_scaled[i, j ])\n",
        "        features_matrix_aug[j].append(X_scaled[(i + 1), j ])\n",
        "  else:\n",
        "      #sino generar los series y hacer el append al dataframe de la row\n",
        "      row_dict_orig, row_dict_aug = {}, {}\n",
        "      for k in range(X_scaled.shape[1]):\n",
        "        row_dict_orig[k] = features_matrix_orig[k]\n",
        "        row_dict_aug[k] = features_matrix_aug[k]\n",
        "      row_dict_orig[\"label\"] = class_current\n",
        "      row_dict_aug[\"label\"] = class_current\n",
        "      #print(features_matrix_orig)\n",
        "      df_transformer = df_transformer.append(row_dict_orig, ignore_index=True)\n",
        "      df_transformer = df_transformer.append(row_dict_aug, ignore_index=True)\n",
        "      features_matrix_orig = []\n",
        "      features_matrix_aug = []\n",
        "      for i in range(X_scaled.shape[1]):\n",
        "        features_matrix_orig.append([])\n",
        "        features_matrix_aug.append([])\n",
        "      class_prev = class_current\n",
        "  \n",
        "  class_current = \"\"\n",
        "\n",
        "df_transformer.to_excel(\"/content/gdrive/My Drive/your_directory/LIBRAS Data/All_Vocab_Transformer_28112022.xlsx\")"
      ],
      "metadata": {
        "id": "KcLjXjConF3B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}